{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70d3240e",
   "metadata": {},
   "source": [
    "### General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9166debd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn \n",
    "import torch.nn.init as init\n",
    "from IPython.display import Image \n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import pickle\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "seed = 12345\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b8941b",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e574be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast, GPT2LMHeadModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b031eb97",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ab8b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pickle.load(open('okcupid_train.pkl', 'rb'))\n",
    "val = pickle.load(open('okcupid_val.pkl', 'rb'))\n",
    "test = pickle.load(open('okcupid_test.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b99ba5",
   "metadata": {},
   "source": [
    "### Dataset to handle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5425003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        self.tokenizer = GPT2TokenizerFast.from_pretrained('distilgpt2')\n",
    "        self.tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.batches = []\n",
    "        \n",
    "        for i in range(int(len(self.dataset) / batch_size)):\n",
    "            batch = self.dataset[i * self.batch_size : (i + 1) * self.batch_size]\n",
    "            self.batches += [self.tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\")]\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        return self.batches[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90093658",
   "metadata": {},
   "source": [
    "### Preparing the data for training. BATCH SIZE is specified here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "145cd9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12f49101",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = GPTDataset(train, batch_size)\n",
    "val_dataset = GPTDataset(val, batch_size)\n",
    "test_dataset = GPTDataset(test, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455bdccf",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c118312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, optimizer, scheduler, train_dataset, device, epoch=5, \n",
    "               val_dataset=None):   \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for t in tqdm(range(epoch)):\n",
    "        batches = 0 \n",
    "        total = 0\n",
    "        model.train()       \n",
    "        total_loss = 0\n",
    "        for batch_idx, x in tqdm(list(enumerate(train_dataset))):\n",
    "            batches += 1\n",
    "            x = x.to(device)\n",
    "            \n",
    "            output = model(**x, labels=x['input_ids'])\n",
    "            \n",
    "            loss = output[0]\n",
    "            total_loss += loss.sum().detach().item()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(loss.sum().detach().item())\n",
    "            \n",
    "        train_losses += [total_loss / batches]\n",
    "        \n",
    "        if val_dataset is not None:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                total_loss = 0\n",
    "                batches = 0 \n",
    "                total = 0\n",
    "                for batch_idx, x in enumerate(val_dataset):\n",
    "                    batches += 1\n",
    "                    x = x.to(device)\n",
    "\n",
    "                    output = model(**x, labels=x['input_ids'])\n",
    "                    loss = output[0]\n",
    "                    total_loss += loss.sum().detach().item()\n",
    "\n",
    "                val_losses += [total_loss / batches]\n",
    "                \n",
    "        print(\"[EPOCH]: %i, [TRAIN LOSS]: %.6f\" % (t, train_losses[-1]))\n",
    "        if val_dataset is not None:\n",
    "            print(\"[EPOCH]: %i, [VAL LOSS]: %.6f\" % (t, val_losses[-1]))\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a38cc9",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8865007d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc5abfd6c16b4af8bffa1056030adb2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64e8a464f6e48849cbdac09294f07db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/452 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('distilgpt2')\n",
    "#model = model.cuda()\n",
    "model.resize_token_embeddings(len(train_dataset.tokenizer))\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "device = torch.device('cpu')\n",
    "train_losses, val_losses = train_loop(model=model, optimizer=optimizer,\n",
    "                                      scheduler=scheduler, \n",
    "                                      train_dataset=train_dataset, \n",
    "                                      device=device, epoch=20, val_dataset=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bafc055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681eef63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
